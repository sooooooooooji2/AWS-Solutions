#6. A사는 NFS를 사용하여 대용량 비디오 파일을 사내 네트워크 연결 스토리지에 저장합니다. 각 비디오 파일의 크기는 1MB에서 500GB 사이입니다. 
총 스토리지 용량은 70TB이며 더 이상 증가하지 않습니다. 그 회사는 비디오 파일을 아마존 S3로 옮기기로 결정했습니다. 회사는 가능한 최소 네트워크 대역폭을 사용하면서 비디오 파일을 
가능한 한 빨리 마이그레이션해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?
A. S3 버킷을 만듭니다. S3 버킷에 쓸 수 있는 권한이 있는 IAM 역할을 만듭니다. AWS CLI를 사용하여 모든 파일을 S3 버킷에 로컬로 복사합니다.
B. AWS Snowball Edge 작업을 생성합니다. 구내에서 스노우볼 에지 장치를 수신합니다. Snowball Edge 클라이언트를 사용하여 데이터를 장치로 전송합니다. 
AWS가 데이터를 Amazon S3로 가져올 수 있도록 디바이스를 반환합니다.
C. 구내에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 공용 서비스 끝점을 만듭니다. S3 버킷을 만듭니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다.
새 파일 공유를 S3 버킷으로 지정합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.
D. 사내 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 구내에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 VIF(Public Virtual Interface)를 생성합니다. 
S3 버킷을 만듭니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유를 S3 버킷으로 지정합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.

#7. A사는 수신 메시지를 수집하는 응용 프로그램을 가지고 있습니다. 수십 개의 다른 애플리케이션과 마이크로 서비스는 이러한 메시지를 빠르게 소비합니다. 메시지의 수는 급격하게 변화하며 때로는 
초당 10만 개로 갑자기 증가한다. 이 회사는 솔루션을 분리하고 확장성을 높이기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?
A. Amazon Kinesis Data Analytics에 메시지를 유지합니다. 메시지를 읽고 처리하도록 소비자 응용 프로그램을 구성합니다.
B. 자동 스케일링 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포하여 CPU 메트릭을 기반으로 EC2 인스턴스 수를 확장합니다.
C. 단일 샤드로 Amazon Kinesis Data Streams에 메시지를 작성합니다. AWS 람다 기능을 사용하여 메시지를 사전 처리하고 Amazon DynamoDB에 저장합니다. 
메시지를 처리하기 위해 DynamoDB에서 읽도록 소비자 애플리케이션을 구성합니다.
D. 여러 개의 Amazon Simple Queue Service(Amazon SOS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 항목에 메시지를 게시합니다. 
큐의 메시지를 처리하도록 소비자 응용 프로그램을 구성합니다.

#8. A사는 분산 애플리케이션을 AWS로 마이그레이션하고 있다. 애플리케이션은 다양한 워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성됩니다. 
이 회사는 복원력과 확장성을 극대화하는 솔루션으로 애플리케이션을 현대화하고자 합니다. 솔루션 설계자는 이러한 요구사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까?
A. Amazon SQS(Simple Queue Service) 큐를 작업의 대상으로 구성합니다. 자동 스케일링 그룹에서 관리되는 Amazon EC2 인스턴스를 사용하여 컴퓨팅 노드를 구현합니다. 예약된 스케일링을 사용하도록 EC2 자동 스케일링을 구성합니다.
B. Amazon SQS(Simple Queue Service) 큐를 작업의 대상으로 구성합니다. 자동 스케일링 그룹에서 관리되는 Amazon EC2 인스턴스를 사용하여 컴퓨팅 노드를 구현합니다. 대기열 크기를 기준으로 EC2 자동 스케일링을 구성합니다. 최다 투표율
C. 자동 스케일링 그룹에서 관리되는 Amazon EC2 인스턴스를 사용하여 기본 서버 및 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail을 구성하십시오. 주 서버의 로드를 기준으로 EC2 자동 스케일링을 구성합니다.
D. 자동 스케일링 그룹에서 관리되는 Amazon EC2 인스턴스를 사용하여 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 
컴퓨팅 노드의 로드를 기반으로 EC2 자동 스케일링을 구성합니다.

#9. 한 회사가 데이터 센터에서 SMB 파일 서버를 실행하고 있습니다. 파일 서버는 파일이 생성된 후 처음 며칠 동안 자주 액세스하는 대용량 파일을 저장합니다. 7일 후에는 파일에 거의 액세스할 수 없습니다.
총 데이터 크기가 증가하고 있으며 회사의 총 스토리지 용량에 근접합니다. 솔루션 설계자는 가장 최근에 액세스한 파일에 대한 짧은 지연 시간의 액세스 손실 없이 회사의 가용 스토리지 공간을 늘려야 합니다. 솔루션 설계자는 향후 스토리지 문제를 방지하기 위해 파일 라이프사이클 관리 기능도 제공해야 합니다.
이러한 요구사항을 충족하는 솔루션은 무엇입니까?
A. AWS DataSync를 사용하여 SMB 파일 서버에서 AWS로 7일 이상 지난 데이터를 복사합니다.
B. Amazon S3 File Gateway를 생성하여 회사의 스토리지 공간을 확장합니다. 7일 후 S3 Glacier Deep Archive로 데이터를 전환하는 S3 Lifecycle 정책을 생성합니다.
C. Amazon FSx for Windows File Server 파일 시스템을 생성하여 회사의 저장소 공간을 확장합니다.
D. 각 사용자의 컴퓨터에 유틸리티를 설치하여 Amazon S3에 액세스합니다. 7일 후 데이터를 S3 Glacier Flexible Retrieve로 전환하기 위한 S3 Lifecycle 정책을 만듭니다.

#9. A사는 AWS에서 전자 상거래 웹 애플리케이션을 구축하고 있다. 애플리케이션은 처리할 새 주문에 대한 정보를 Amazon API Gateway REST API로 보냅니다. 
이 회사는 주문이 접수된 순서대로 처리되도록 하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?
A. 응용 프로그램이 주문을 받을 때 API Gateway 통합을 사용하여 Amazon Simple Notification Service(Amazon SNS) 항목에 메시지를 게시합니다. AWS 람다 함수를 항목에 등록하여 처리합니다.
B. 애플리케이션이 주문을 수신할 때 API 게이트웨이 통합을 사용하여 Amazon SQS(Simple Queue Service) FIFO 큐로 메시지를 보냅니다. 처리를 위해 AWS 람다 함수를 호출하도록 SQS FIFO 대기열을 구성합니다.
C. 응용 프로그램이 주문을 처리하는 동안 API Gateway 인증자를 사용하여 요청을 차단합니다.
D. 애플리케이션이 주문을 수신할 때 API 게이트웨이 통합을 사용하여 Amazon SQS(Simple Queue Service) 표준 대기열로 메시지를 보냅니다. 처리를 위해 AWS 람다 함수를 호출하도록 SQS 표준 대기열을 구성합니다.




---------------------------------------------------------------------------------------------------------------------------------------
#6. A company uses NFS to store large video files in on-premises network attached storage. Each video file ranges in size from 1 MB to 500 GB. The
total storage is 70 TB and is no longer growing. The company decides to migrate the video files to Amazon S3. The company must migrate the
video files as soon as possible while using the least possible network bandwidth.
Which solution will meet these requirements?
A. Create an S3 bucket. Create an IAM role that has permissions to write to the S3 bucket. Use the AWS CLI to copy all files locally to the S3
bucket.
B. Create an AWS Snowball Edge job. Receive a Snowball Edge device on premises. Use the Snowball Edge client to transfer data to the
device. Return the device so that AWS can import the data into Amazon S3.
C. Deploy an S3 File Gateway on premises. Create a public service endpoint to connect to the S3 File Gateway. Create an S3 bucket. Create a
new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the
S3 File Gateway.
D. Set up an AWS Direct Connect connection between the on-premises network and AWS. Deploy an S3 File Gateway on premises. Create a
public virtual interface (VIF) to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point
the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway.


#7. A company has an application that ingests incoming messages. Dozens of other applications and microservices then quickly consume these
messages. The number of messages varies drastically and sometimes increases suddenly to 100,000 each second. The company wants to
decouple the solution and increase scalability.
Which solution meets these requirements?
A. Persist the messages to Amazon Kinesis Data Analytics. Configure the consumer applications to read and process the messages.
B. Deploy the ingestion application on Amazon EC2 instances in an Auto Scaling group to scale the number of EC2 instances based on CPU
metrics.
C. Write the messages to Amazon Kinesis Data Streams with a single shard. Use an AWS Lambda function to preprocess messages and store
them in Amazon DynamoDB. Configure the consumer applications to read from DynamoDB to process the messages.
D. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon
SOS) subscriptions. Configure the consumer applications to process the messages from the queues.

#8. A company is migrating a distributed application to AWS. The application serves variable workloads. The legacy platform consists of a primary
server that coordinates jobs across multiple compute nodes. The company wants to modernize the application with a solution that maximizes
resiliency and scalability.
How should a solutions architect design the architecture to meet these requirements?
A. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon
EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling to use scheduled scaling.
B. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon
EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling based on the size of the queue. Most Voted
C. Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure
AWS CloudTrail as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the primary server.
D. Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure
Amazon EventBridge (Amazon CloudWatch Events) as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the
compute nodes.

#9. A company is running an SMB file server in its data center. The file server stores large files that are accessed frequently for the first few days after
the files are created. After 7 days the files are rarely accessed.
The total data size is increasing and is close to the company's total storage capacity. A solutions architect must increase the company's available
storage space without losing low-latency access to the most recently accessed files. The solutions architect must also provide file lifecycle
management to avoid future storage issues.
Which solution will meet these requirements?
A. Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS.
B. Create an Amazon S3 File Gateway to extend the company's storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier
Deep Archive after 7 days. 
C. Create an Amazon FSx for Windows File Server file system to extend the company's storage space.
D. Install a utility on each user's computer to access Amazon S3. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible
Retrieval after 7 days.

#10. A company is building an ecommerce web application on AWS. The application sends information about new orders to an Amazon API Gateway
REST API to process. The company wants to ensure that orders are processed in the order that they are received.
Which solution will meet these requirements?
A. Use an API Gateway integration to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when the application
receives an order. Subscribe an AWS Lambda function to the topic to perform processing.
B. Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) FIFO queue when the application
receives an order. Configure the SQS FIFO queue to invoke an AWS Lambda function for processing. Most Voted
C. Use an API Gateway authorizer to block any requests while the application processes an order.
D. Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) standard queue when the
application receives an order. Configure the SQS standard queue to invoke an AWS Lambda function for processing.

